# Welcome to my Jupyter Book                                      
                                                               Dévise: Travail, Travail, Travail.

Bienvenue dans mon portfolio académique en data science.

Je vous souhaite mes voeux les meilleurs pour ce nouvel an 2024, santé,bonheur,amour,accomplissement dans vos différents projets, tout ce qu'il y'a de meilleurs.

Je me nomme MAHI NDOUNG RODRIGUE.

Je suis un jeune étudiant camerounais,débutant dans le monde de la science des données,particulièrement en data scientist.je suis un pur autodidacte, j'ai commencé à étudier la programmation sur python,R... sur youtube, puis je me suis inscrit à WORDLQUANT UNIVERSITY(USA) où j'ai passé l'examen de contrôle de connaissances sur python, statistique, mathématique et bien plus.Au bout de six mois j'ai obtenu la certification du [Laboratoire des sciences de données appliquées WORLDQUANT UNIVERSITY](https://www.credly.com/badges/1dc81b29-d1cd-4f9f-9804-79d136b33ec3/public_url) où nous avons travaillés sur 8 projets avec les données réelles entre autres:

✔️ Dans le projet 1, nous avons travaillé avec un ensemble de données contenant 21 000 propriétés à vendre au Mexique via le site Web immobilier [Properati.com](https://properati.com/). Notre objectif était de déterminer si les prix de vente sont davantage influencés par la taille ou l’emplacement de la propriété.
J'ai appris à organiser les informations à l’aide des structures de données Python de base, à importer des données à partir de fichiers CSV et les nettoyer à l’aide de la bibliothèque pandas, à créer des visualisations de données comme des nuages de points et des boîtes à moustaches, à examiner la relation entre deux variables à l’aide de la corrélation.

✔️ Dans le projet 2, nous nous sommes appuyés sur des compétences acquisent au projet 1. nous sommes passés de la science des données descriptive à la science des données prédictive. Nous avons toujours travaillez sur l’immobilier, créant un modèle d’apprentissage automatique qui prédit les prix des appartements à Buenos Aires, en Argentine.
J'ai appris à créer un modèle de régression linéaire à l’aide de la bibliothèque scikit-learn, à créer un pipeline de données pour imputer les valeurs manquantes et coder les caractéristiques catégorielles, à améliorer les performances du modèle en réduisant le surapprentissage, à créer un tableau de bord dynamique pour interagir avec modèle final.

✔️ Dans le projet 3, nous avons travaillés avec des données provenant de l’une des plus grandes plateformes de données ouvertes d’Afrique, [openAfrica](https://open.africa/). Nous avons examinés les données sur la qualité de l’air de Nairobi, Lagos et Dar es Salaam ; et construire un modèle de série chronologique pour prédire les lectures de PM 2,5 tout au long de la journée.
J'ai appris à obtenir des données en interrogeant une base de données MongoDB, à préparer des données de séries chronologiques pour l’analyse, à créer un modèle d’autorégression, à améliorer un modèle en ajustant ses hyperparamètres.

✔️ Dans le projet 4, Nous avons travaillés avec les données [d’Open Data Nepal](https://opendatanepal.com/) pour créer un modèle permettant de prédire les dommages causés aux bâtiments par [le tremblement de terre de 2015](https://en.wikipedia.org/wiki/April2015Nepalearthquake) au Népal. Vous travaillerez principalement avec des données du district de Gorkha, avec des exemples supplémentaires de Ramechhap. _
J'ai appris à obtenir des données en interrogeant une base de données SQL, à construire un modèle de régression logistique pour la classification, à construire un modèle d’arbre de décision pour la classification, à intégrer des considérations éthiques dans la modélisation.

✔️ Dans le projet 5, nous avons explorés les données recueillies par une équipe d’économistes polonais étudiant la faillite. Notre objectif etait de construire un modèle capable de prédire si une entreprise fera faillite ou non.
J'ai appris à naviguer dans un système de fichiers à partir de la ligne de commande Linux, à Charger et enregistrer des fichiers à l’aide de Python, à traiter les données déséquilibrées à l’aide de techniques de rééchantillonnage, à évaluer un modèle à l’aide de métriques de classification telles que la précision et le rappel.

✔️ Dans le projet 6, Nous avons utilisés les données de l’Enquête sur les finances des consommateurs de 2019. Tout d’abord, nous avons identifiés les ménages qui ont de la difficulté à obtenir du crédit. Nous avons ensuite créer un modèle pour segmenter ces ménages en sous-groupes. Enfin, nous avons créer une application Web interactive pour partager notre travail.Il s'agissait d'un  projet sur un exemple d’apprentissage non supervisé, en particulier de clustering. Qui peut être utilisé dans des contextes commerciaux pour le marketing ou la segmentation de la clientèle ou dans des contextes sociologiques pour étudier la stratification sociale.
J'ai appris à Comparez les caractéristiques des sous-groupes à l’aide d’un graphique à barres côte à côte, à Créez un modèle de clustering k-means à éffectuez la sélection des caractéristiques pour le clustering en fonction de la variance à réduire les données de grande dimension à l’aide de l’analyse en composantes principales (ACP), à Concevoir, à construire et déployer une application web Dash.

✔️ Dans le projet 7 c'est un exemple de test A/B, également connu sous le nom d’expérience contrôlée randomisée.Ici, il était question d'aider WQU pour améliorer ses programmes ! Nicholas et l’équipe ont remarqué que de nombreux candidats au DS Lab ne répondent jamais au quiz d’admission. Dans ce projet, nous allons concevoir et mener une expérience pour voir si nous pouvons augmenter le nombre de réponses aux quiz.

Dans le secteur privé, les tests A/B sont utilisés pour améliorer des choses comme le marketing par e-mail et la tarification des produits. En politique, ils peuvent être utilisés pour tester les messages de campagne. Des scientifiques de toutes sortes les utilisent dans leurs recherches.
J'ai appris à Construire une carte choroplèthe pour montrer la répartition des élèves ADSL dans le monde, à Créer une classe Python personnalisée pour implémenter des processus ETL, à Concevoir une expérience et à analyser les résultats à l’aide d’un test du chi carré, à Créer une application web interactive qui suit un modèle de conception à trois niveaux.

✔️ Dans Project 8  nous avons crée un modèle pour prédire la volatilité à la Bourse de Bombay.
Tout d’abord, nous avons explorer les données boursières de deux entreprises à l’aide de l’API boursière AlphaVantage. Ensuite, nous avons utilisé ces données pour calculer la volatilité et construire un modèle pour la prédire. Enfin, nous allons déployés notre modèle en créant notre propre API pour servir les prédictions.
J'ai appris à Obtenir des données à partir d’une API Web en effectuant des requêtes HTTP, à transformer et charger des données dans une base de données SQL à l’aide de classes Python personnalisées, à Calculer la volatilité des actifs et construisez un modèle GARCH pour la prédire, à Créer votre propre API Web et votre propre serveur pour servir les prédictions de votre modèle.
Ces différents projets ne sont pas permis d'être publiés sur des sites publics par l'université.


A présent, je fais la [certification professionnelle IBM data science](https://www.coursera.org/professional-certificates/ibm-data-science#courses) en ligne sur coursera.Elle comporte 12 cours:

terminé ✔️ [cours 1](https://www.coursera.org/learn/what-is-datascience?specialization=ibm-data-science),

[cours 2](https://www.coursera.org/learn/open-source-tools-for-data-science?specialization=ibm-data-science).
terminé ✔️: cliquer ici pour voir la  certification [Tools for data science](https://www.credly.com/badges/a6d008df-4d62-420a-86b3-af3af1320b5c/public_url),

[cours 3](https://www.coursera.org/learn/data-science-methodology?specialization=ibm-data-science). 
terminé ✔️: cliquer ici pour voir la  certification [Méthodologie de la science des données](https://www.credly.com/badges/4fe99f93-5d77-42d0-85fa-35dce206578c/public_url ),

[cours 4](https://www.coursera.org/learn/python-for-applied-data-science-ai?specialization=ibm-data-science),
terminé ✔️:  cliquer ici pour voir le lien de  la  certification [python pour la science des données, IA et developpement](https://www.credly.com/badges/b0c02fb7-c868-4cf7-af04-15dd95224692/public_url)



[cours 5](https://www.coursera.org/learn/python-project-for-data-science?specialization=ibm-data-science), en cours...

[cours 6](https://www.coursera.org/learn/sql-data-science?specialization=ibm-data-science),
terminé ✔️: cliquer ici pour voir la  certification [BASE DE DONNEES ET SQL POUR LA SCIENCE DES DONNEES AVEC PYTHON](https://www.credly.com/badges/1add142f-5bf0-43fd-9633-f3021b6efc0e/public_url) et [spécialisation en bases de données et SQL avancé Mention d'honneur](https://coursera.org/share/d5eaa31ecee9dfc7b19413418ab32c0f).

[cours 7](https://www.coursera.org/learn/data-analysis-with-python?specialization=ibm-data-science),
terminé ✔️:  cliquer ici pour voir le lien de la  certification [Analyse des données avec python](https://www.credly.com/badges/0860c256-0d7e-4bbd-8023-847cbe339d4e/public_url)


[cours 8](https://www.coursera.org/learn/python-for-data-visualization?specialization=ibm-data-science)
 terminé ✔️:  cliquer ici pour voir le lien de la  certification [VISUALISATION DES DONNEES AVEC PYTHON](https://www.credly.com/badges/6b0fa382-2f74-47c0-9d9c-566d1e08ec45/public_url).
 Quelques tableau de bord que j'ai eu à créer: [dashboard](https://www.linkedin.com/in/rodrigue-mahi-39466a296/recent-activity/videos/?trk=public_profile-settings_see-all-posts)
 
[cours 9](https://www.coursera.org/learn/machine-learning-with-python?specialization=ibm-data-science), en cours...
 
[cours 10](https://www.coursera.org/learn/applied-data-science-capstone?specialization=ibm-data-science), en cours...

[cours11](https://www.coursera.org/learn/generative-ai-elevate-your-data-science-career?specialization=ibm-data-science), en cours...

[cours12](https://www.coursera.org/learn/career-guide-and-interview-prep-for-data-science-pc?specialization=ibm-data-science), en cours...

Dans ce portefolio je mettrai en exergue une partie de mes travaux que j'ai réalisé parallèlement d'une manière individuel en même temps que je me fais former.
En outre, dans un premier temps je vous présenterai au chapitre 1 mes cinq projets élaboré de façon autonôme avec python.
Ensuite, dans un second temps j'éluciderai au chapitre 2 ma prise en main avec R.
Enfin, dans le chapitre 3 je mettrais l'accent sur quelques pratiques de la statistique, les fonctions,listes pour la data science, webscraping, plolty express.

Pour plus d'information veuillez me rejoindre sur  [linkedin](https://www.linkedin.com/public-profile/settings?trk=d_flagship3_profile_self_view_public_profile) ou sur mon [github](mahi-ndoung-rodrigue (github.com)) for more information.

Check out the content pages bundled with this sample book to see more.

```{tableofcontents}
```
